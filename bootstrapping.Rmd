---
title: "bootstrapping"
author: "Matthew Lawlor"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)
library(p8105.datasets)

set.seed(1)
```


## Simulate data

```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

Plot the datasets

```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 
```

Review linear regression

```{r}
lm(y ~ x, data = sim_df_const) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Overall variance is the same, but review of plot suggests variance in nonconst_df is nonconstant which limits applicabilty of normal inference approaches. Bootstrapping can be used to make inference on a dataset with unknown distribution.

## Draw one bootstrap sample

Build a bootstrap function

```{r}
boot_sample = function(df) {
  
  sample_frac(df, 1, replace = TRUE) %>% 
    arrange(x)
  
}
```

Check how it works (repeat to simulate bootstrapping)

```{r}
boot_sample(sim_df_nonconst) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .3) +
  stat_smooth(method = "lm")
```

```{r}
boot_sample(sim_df_nonconst) %>% 
  lm(y~ x, data = .) %>% 
  broom::tidy()
```

