---
title: "bootstrapping"
author: "Matthew Lawlor"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)
library(p8105.datasets)

set.seed(1)
```


## Simulate data

```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

Plot the datasets

```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 
```

Review linear regression

```{r}
lm(y ~ x, data = sim_df_const) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

lm(y ~ x, data = sim_df_nonconst) %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Overall variance is the same, but review of plot suggests variance in nonconst_df is nonconstant which limits applicabilty of normal inference approaches. Bootstrapping can be used to make inference on a dataset with unknown distribution.

## Draw one bootstrap sample

Build a bootstrap function

```{r}
boot_sample = function(df) {
  
  sample_frac(df, 1, replace = TRUE) %>% 
    arrange(x)
  
}
```

Check how it works (repeat to simulate bootstrapping)

```{r}
boot_sample(sim_df_nonconst) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .3) +
  stat_smooth(method = "lm")
```

```{r}
boot_sample(sim_df_nonconst) %>% 
  lm(y~ x, data = .) %>% 
  broom::tidy()
```

## Many smaples and analysis

```{r}
boot_straps = 
  tibble(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst))
  )
```

Can I run analysis on these? Yes same as before

```{r}
boot_results = 
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(y ~ x, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)
```

What do I have now? 

This dataframe holds output of bootstrap linear models with random sampling and replacement. Now we have a normal distribution of intercept and slope from these repeat bootstrap models to get standard deviation of these measures

```{r}
boot_results %>% 
  group_by(term) %>% 
  summarize(
    mean_est = mean(estimate),
    sd_est = sd(estimate)
  )
```

Look at the distributions

```{r}
boot_results %>% 
  filter(term == "x") %>% 
  ggplot(aes(x = estimate)) +
  geom_density()
```

Construct a bootstrap confidence interval

```{r}
boot_results %>% 
  group_by(term) %>% 
  summarize(
    ci_lower = quantile(estimate, 0.025),
    ci_upper = quantile(estimate, 0.975)
  )
```

## Bootstrap using modelr

Can we simplify anything from the above procedures?

```{r}
sim_df_nonconst %>% 
  bootstrap(1000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(y ~ x, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results) %>% 
    group_by(term) %>% 
  summarize(
    mean_est = mean(estimate),
    sd_est = sd(estimate)
  )
```

note the bootstrap function stores resamples rather than dataframes (need to convert to dataframes to use the use the mgcv package as seen in cross validation)
